<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Project Summary on Community detection and analysis of American news agencies</title><link>https://rsm-git.github.io/</link><description>Recent content in Project Summary on Community detection and analysis of American news agencies</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://rsm-git.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Data description</title><link>https://rsm-git.github.io/data-description/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rsm-git.github.io/data-description/</guid><description>The data used for this project is a subset of All the News 2.0, which contains 2,677,878 news articles American publications spanning from January 1, 2016 to April 2, 2020.
We chose to work with articles from the two publications with the most articles in the dataset: Reuters with 840,094 articles, and The New York Times (NYT) with 252,259 authors.
The dataset contains 10 features: authors, title, article text, url, section, publication and four features describing the time of publication.</description></item><item><title>Network analysis</title><link>https://rsm-git.github.io/network-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rsm-git.github.io/network-analysis/</guid><description>For both The New York Times and Reuters we construct networks based on collaboration of articles. A node represents an author and a connection between two nodes represent collaboration. The size of the nodes will be scaled by the number of articles an author has published. The networks are undirected and unweighted as the collaborative connection is mutual. With the two networks we will be able to discern the differences in how the two news agencies collaborate between authors.</description></item><item><title>Text analysis</title><link>https://rsm-git.github.io/text-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://rsm-git.github.io/text-analysis/</guid><description>Word Clouds To examine the textual differences of the two publication, we chose to look at word clouds and sentiment. The word clouds are generated by removing stop words and punctuation and calculating the tf-idf for each word. For the sentiment analysis, we used a BERT transformer model from the Huggingface library. See the explainer notebook for more information.
We are interested in examining how the two publications portray the same subject.</description></item></channel></rss>