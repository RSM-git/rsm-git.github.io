[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Created a graph consisting of journalists\nClassical NLP methods\nGraph analysis & statistics\n\nView project\n\n\n\n\nCollected data and trained models\nDeployed models to Azure exposed as FastAPI endpoints\nMultiple cases: Object detection, Movie rating prediction, Reinforcement learning\n\n\n\n\n\nAchieved SOTA performance at the time of development\nCollected data for training with the Twitter(X) API\nDeployed solution with a light HTML/CSS frontend\nInference on articles from Scopus"
  },
  {
    "objectID": "projects.html#selected-projects",
    "href": "projects.html#selected-projects",
    "title": "Projects",
    "section": "",
    "text": "Created a graph consisting of journalists\nClassical NLP methods\nGraph analysis & statistics\n\nView project\n\n\n\n\nCollected data and trained models\nDeployed models to Azure exposed as FastAPI endpoints\nMultiple cases: Object detection, Movie rating prediction, Reinforcement learning\n\n\n\n\n\nAchieved SOTA performance at the time of development\nCollected data for training with the Twitter(X) API\nDeployed solution with a light HTML/CSS frontend\nInference on articles from Scopus"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My site",
    "section": "",
    "text": "Hi, I’m Rasmus a AI / Data Scientist\nThroughout the last five years I have gained experience within:\n\nPython\nMachine Learning\nDeep Learning\nData Visualization\nData Analysis\n\nThis site showcases acts as a portfolio for some of my projects, and tells a bit about myself."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "I’ve always been interested in mathematics, physics, and technology which is able to describe our world.\nI enjoy programming primarily in Python, but I also dabble in some Lua, Rust, C, and C++.\nAppart from programming I genuinely enjoy learning new things, biking, and going for a nice refreshing hike."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About me",
    "section": "Education",
    "text": "Education\n\n(10.33 / 12.00 GPA) Master’s degree in Mathematical Modelling and Computation [2023-2025 at DTU]\n(10.13 / 12.00 GPA) Bachelor’s degree in Artificial Intelligence and Data [2020-2023 at DTU]"
  },
  {
    "objectID": "projects/community_detection/community_detection.html",
    "href": "projects/community_detection/community_detection.html",
    "title": "Community detection in news media",
    "section": "",
    "text": "To see the see the code for the analysis see the notebook."
  },
  {
    "objectID": "projects/community_detection/community_detection.html#what-is-this-project-about",
    "href": "projects/community_detection/community_detection.html#what-is-this-project-about",
    "title": "Community detection in news media",
    "section": "What is this project about?",
    "text": "What is this project about?\nThis project analyses how authors collaborate within and across Reuters and The New York Times, the analysis is focused both on the collaborative nature of journalism and how the journalists write."
  },
  {
    "objectID": "projects/community_detection/community_detection.html#data",
    "href": "projects/community_detection/community_detection.html#data",
    "title": "Community detection in news media",
    "section": "Data",
    "text": "Data\nThe data for this project is a subset of All The News 2.0, which is a collection of articles collected from scraping the web with a total of 2,677,878 articles published in the period from January 1, 2016 to April 2, 2020. The dataset contains articles froom several different media organizations with Reuters and NYT being the largest.\nThis project focused on Reuters and NYT with 840,094 and 252,259 articles respectively.\nThe dataset has seven features: authors, title, article text, url, section, publication, and the day the article was published. Of the seven features, three are used for this project: authors, article text, and section.\n\nPreprocessing\nSince the dataset was collected by scraping the web, it did not come as a surprise that many of the samples are missing features. To filter the unwanted entries the following preprocessing steps were carried out:\n\nRemove articles not published by Reuters or NYT\nRemove articles missing either authors, section, or article text\nRemove articles in sections that has less than 100 articles\nRemove authors that have written less than 5 articles\nRemove articles with less than 2 authors\n\nThe fifth preprocessing step discards a large amount of data since most articles are written by a single author, but was necessary since the goal of this project was to investigate collaboration within news media organizations.\nThe table below displays statistics of the dataset post preprocessing.\n\n\n\n\nReuters\nNYT\n\n\n\n\nNumber of articles\n57,128\n23,796\n\n\nNumber of sections\n39\n21\n\n\nNumber of unique authors\n1,951\n1,318\n\n\nAverage words per article\n622\n1204\n\n\nAverage articles per author\n29\n18\n\n\n\nThe two figures below showcase the most common articles for the two organizations\n\n\n\n\n\nReuters sections\n\n\n\n\n\n\nNYT sections\n\n\n\n\nLooking at the distribution of article length for each of the two organizations we observe that NYT articles on average are twice as long as Reuters articles.\n\n\n\n\n\nReuters article length distribution\n\n\n\n\n\n\nNYT article length distribution"
  },
  {
    "objectID": "projects/community_detection/community_detection.html#network-analysis",
    "href": "projects/community_detection/community_detection.html#network-analysis",
    "title": "Community detection in news media",
    "section": "Network analysis",
    "text": "Network analysis\nFor both organizations the networks are constructed based on collaboration. A node in the network represents an author and a connection represents that two authors have collaborated. The nodes are scaled based on the number of articles authored by the given author. The networks are undirected and unweighted as the collaborative connection is assumed to be mutual.\n\nThe New York Times\n\n\n\nNYT collaboration network\n\n\nSome nodes (authors) will be discarded as they are not connected to the largest connected component of the graph and as such does not provide any meaningful information regarding the community structure of the network.\nFor the largest connected component the authors are color coded by their most published section as seen in the network below\n \nNext the Louvain community detection algorithm was run on the largest connected component of the NYT network yielding the following partitioning of the network.\n\n\n\nNYT Louvain partitioning\n\n\nAlthough there are some differences in the partitioning given by the Louvain algorithm and the authors’ most common section, there are also many similarities.\nTo test whether the community structure is better than a random partitioning a randomization experiment was carried out by using the double edge swap algorithm. The randomization experiment was repeated 500 times, to quantify the uncertainty of a random partitioning, the community structure of the networks is quantified by computing the modularity of the network.\n\n\n\nNYT Modularity\n\n\nThe modularity of both the partitionings are significantly better than the random partitionings given by the double edge swap algorithm, with the partitioning given by the Louvain algorithm being slightly better. However, this is not surprising as the Louvain algorithm optimizes the modularity of the network.\n\n\nReuters\nAn identical approach was carried out for the data from Reuters\n\n\n\nReuters collaboration network\n\n\nOnce again we discard the nodes which are not connected to the largest connected component. Comparing the Reuters network to the NYT network we observe that the Reuters network is much more densely connected.\n\n\n\nReuters largest connected component\n\n\nAnd the partitioning yielded by the Louvain algorithm\n\n\n\nReuters Louvain partitioning\n\n\nPerforming a similar randomization experiment with the Reuters network\n\n\n\nReuters Modularity\n\n\nUnlike with the NYT network there is a much larger discrepancy between the section partitioning and the partitioning given by Louvain algorithm. However, it is important to note that Reuters many more sections which can overlap due to similarities, as the Louvain algorithm produces 9 communities for NYT (roughly 43% of the sections), and 11 for Reuters (roughly 28% of the sections)."
  },
  {
    "objectID": "projects/community_detection/community_detection.html#text-analysis",
    "href": "projects/community_detection/community_detection.html#text-analysis",
    "title": "Community detection in news media",
    "section": "Text analysis",
    "text": "Text analysis\nTo examine the linguistic differences between the two organizations, word clouds and sentiment analysis was carried out. The word clouds are generated by removing stop words and punctuation and calculating the TF-IDF for articles within a given section. The sentiment analysis was carried out using BERT.\n\nWord clouds\nWhen examining the word clouds produced for the politically inclined sections we see that the American 2016 election has an emphasis in both Reuthers’ Politics section and NYT’s US section.\n\n\n\n\n\n\n\nThere are no obvious outliers regarding the language used within the two organizations, it would have been interesting to see how an organization such as Fox News portrayed the 2016 election.\n\n\nSentiment analysis\nUsing BERT to quantify the sentiment for a given article the following distribution of sentiment was obtained\n\n\n\n\nReuters\nNYT\n\n\n\n\nNegative\n47,651 (83%)\n17,376 (73%)\n\n\nNeutral\n5,812 (10%)\n3,384 (14%)\n\n\nPositive\n3,666 (7%)\n3,036 (13%)\n\n\n\nIn general news articles and headlines are generally written with negative sentiment because it also attracts clicks as it will often be more exciting."
  }
]